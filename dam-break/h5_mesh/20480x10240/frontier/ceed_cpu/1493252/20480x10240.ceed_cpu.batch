#!/bin/bash
#SBATCH -A csc314
#SBATCH -J ceed_cpu
#SBATCH -o %x-%j.out
#SBATCH -t 0:30:00
#SBATCH -p batch
#SBATCH -N 16

#N=1;n=56
#N=2;n=112
#N=4;n=224
#N=8;n=448
N=16;n=896

GRID_ID=20480x10240

mkdir ${SLURM_JOB_ID}
cp ${GRID_ID}.ceed_cpu.batch ${SLURM_JOB_ID}

source /ccs/home/gb9/rdycore/rdycore-e3sm-scripts/modules/modules.frontier.gnugpu

export PETSC_DIR=/ccs/home/gb9/Projects/petsc/petsc_main
export PETSC_ARCH=frontier-gpu-no-debug-gcc-11-2-0-a7898f52c39

RDYCORE=/ccs/home/gb9/rdycore/rdycore/build-${PETSC_ARCH}/bin/rdycore

export LD_LIBRARY_PATH=$PETSC_DIR/$PETSC_ARCH/lib:$LD_LIBRARY_PATH
export GPU_AWARE_MPI=1
export MPICH_GPU_SUPPORT_ENABLED=1

module load craype-accel-amd-gfx90a
module load xpmem/2.6.2-2.5_2.22__gd067c3f.shasta
module load rocm/5.4.0

export PE_MPICH_GTL_DIR_amd_gfx90a="-L${CRAY_MPICH_ROOTDIR}/gtl/lib"
export PE_MPICH_GTL_LIBS_amd_gfx90a="-lmpi_gtl_hsa"

LOG_FILE=${GRID_ID}.n_${n}.${PETSC_ARCH}.ceed_cpu.${SLURM_JOB_ID}.log
LOG_VIEW_FILE=${GRID_ID}.n_${n}.ceed_cpu.${SLURM_JOB_ID}.log_view
YAML_FILE=inputdeck_${GRID_ID}.yaml

#-log_view :${LOG_VIEW_FILE}:ascii_csv \

srun \
-N${N} -n${n} -c1                 \
${RDYCORE}                        \
${YAML_FILE}                      \
-ceed /cpu/self                   \
-ts_monitor                       \
-log_view                         \
-use_gpu_aware_mpi $GPU_AWARE_MPI \
-dm_plex_create_from_hdf5_xdmf    \
2>&1 | tee $LOG_FILE

mv *.${SLURM_JOB_ID}.* ${SLURM_JOB_ID}
