MPIIO WARNING: DVS stripe width of 24 was requested but DVS set it to 1
See MPICH_MPIIO_DVS_MAXNODES in the intro_mpi man page.
DM Object: Parallel Mesh 4 MPI processes
  type: plex
Parallel Mesh in 2 dimensions:
  Number of 0-cells per rank: 44993783 47174653 47817936 44696753
  Number of 1-cells per rank: 89971900 94330825 95616455 89377977
  Number of 2-cells per rank: 44978118 47156173 47798520 44681225
Labels:
  depth: 3 strata with value/size (0 (44993783), 1 (89971900), 2 (44978118))
  celltype: 3 strata with value/size (0 (44993783), 1 (89971900), 4 (44978118))
  boundary_edges: 1 strata with value/size (1 (31328))
Field Field_0:
  adjacency FVM++
slurmstepd: error: Detected 1 oom_kill event in StepId=18277180.0. Some of the step tasks have been OOM Killed.
srun: error: nid003140: task 2: Out Of Memory
srun: Terminating StepId=18277180.0
slurmstepd: error: *** STEP 18277180.0 ON nid003140 CANCELLED AT 2023-11-17T05:53:30 ***
[0]PETSC ERROR: ------------------------------------------------------------------------
[0]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[0]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[0]PETSC ERROR: or see https://petsc.org/release/faq/#valgrind and https://petsc.org/release/faq/
[0]PETSC ERROR: or try https://docs.nvidia.com/cuda/cuda-memcheck/index.html on NVIDIA CUDA systems to find memory corruption errors
[0]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[0]PETSC ERROR: to get more information on the crash.
MPICH ERROR [Rank 0] [job id 18277180.0] [Thu Nov 16 21:53:30 2023] [nid003140] - Abort(59) (rank 0 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 59) - process 0

aborting job:
application called MPI_Abort(MPI_COMM_WORLD, 59) - process 0
[1]PETSC ERROR: ------------------------------------------------------------------------
[1]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[1]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[1]PETSC ERROR: or see https://petsc.org/release/faq/#valgrind and https://petsc.org/release/faq/
[1]PETSC ERROR: or try https://docs.nvidia.com/cuda/cuda-memcheck/index.html on NVIDIA CUDA systems to find memory corruption errors
[1]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[1]PETSC ERROR: to get more information on the crash.
MPICH ERROR [Rank 1] [job id 18277180.0] [Thu Nov 16 21:53:31 2023] [nid003140] - Abort(59) (rank 1 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 59) - process 1

aborting job:
application called MPI_Abort(MPI_COMM_WORLD, 59) - process 1
[3]PETSC ERROR: ------------------------------------------------------------------------
[3]PETSC ERROR: Caught signal number 15 Terminate: Some process (or the batch system) has told this process to end
[3]PETSC ERROR: Try option -start_in_debugger or -on_error_attach_debugger
[3]PETSC ERROR: or see https://petsc.org/release/faq/#valgrind and https://petsc.org/release/faq/
[3]PETSC ERROR: or try https://docs.nvidia.com/cuda/cuda-memcheck/index.html on NVIDIA CUDA systems to find memory corruption errors
[3]PETSC ERROR: configure using --with-debugging=yes, recompile, link, and run 
[3]PETSC ERROR: to get more information on the crash.
MPICH ERROR [Rank 3] [job id 18277180.0] [Thu Nov 16 21:53:33 2023] [nid003140] - Abort(59) (rank 3 in comm 0): application called MPI_Abort(MPI_COMM_WORLD, 59) - process 3

aborting job:
application called MPI_Abort(MPI_COMM_WORLD, 59) - process 3
